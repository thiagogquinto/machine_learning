{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./agaricus_lepiota_small_c.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificação do atributo de saída (class): e → 0 e p → 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = [\n",
    "   ('oe_class', OrdinalEncoder(categories=[['e', 'p']]), ['class']),\n",
    "]\n",
    "\n",
    "ct = ColumnTransformer(transformers=transformers, remainder='passthrough')\n",
    "\n",
    "y_oe = ct.fit_transform(df)\n",
    "\n",
    "df = pd.DataFrame(y_oe, columns=df.columns)\n",
    "df['class'] = df['class'].astype(int)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exclusão de dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atributos_categoricos = ['stalk-root']\n",
    "\n",
    "# transformers = [\n",
    "#     ('imp_cat', SimpleImputer(strategy='constant', fill_value='N'), atributos_categoricos)\n",
    "# ]\n",
    "\n",
    "# ct_imp = ColumnTransformer(\n",
    "#     transformers, remainder='drop'\n",
    "# )\n",
    "\n",
    "# X_imp_vals = ct_imp.fit_transform(df)\n",
    "# X_imp_vals = X_imp_vals[:, 0]  # Selecionar apenas a primeira coluna (stalk-root)\n",
    "\n",
    "# df['stalk-root'] = X_imp_vals\n",
    "# df['stalk-root']\n",
    "\n",
    "df = df.drop('stalk-root', axis=1) \n",
    "\n",
    "df\n",
    "# print(ct_imp.transformers_[0][1].statistics_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificação de atributos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_attr = ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', \n",
    "           'gill-color', 'stalk-shape', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', \n",
    "           'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', \n",
    "           'habitat']\n",
    "\n",
    "for column in nominal_attr:\n",
    "    transformers = [\n",
    "        ('oe_' + column, OneHotEncoder(), [column])\n",
    "    ]\n",
    "\n",
    "    ct_oe = ColumnTransformer(\n",
    "        transformers, remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    X_oe = ct_oe.fit_transform(df)\n",
    "\n",
    "    df[column] = X_oe[:, 0]\n",
    "\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_positive_accuracy(y_true, y_pred):\n",
    "    # positive_samples = (y_true == 1)\n",
    "    return accuracy_score(y_true[y_true == 1], y_pred[y_true == 1])\n",
    "\n",
    "# positive_accuracy_scorer = make_scorer(custom_positive_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV #busca exaustiva para otimização de hiperparâmetro por validação cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação cruzada em dois níveis com KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_knn():\n",
    "    positive_accuracy_scorer = make_scorer(custom_positive_accuracy)\n",
    "\n",
    "    k1 = 10 #controla o número de vias da validação cruzada para estimar o desempenho do modelo\n",
    "    k2 = 5 #controla o número de vida da validação cruzada para otimização de hiperparametros\n",
    "\n",
    "    #usar o protocolo de validação cruzada estratificada\n",
    "    skf = StratifiedKFold(n_splits=k1, shuffle=True, random_state=1)\n",
    "\n",
    "    acuracias = []\n",
    "\n",
    "    #a função split retorna os índices das instâncias que devem ser usadas para o treinamento e o teste.\n",
    "    for idx_treino, idx_teste in skf.split(X, y):\n",
    "        \n",
    "        #extrair as instâncias de treinamento de acordo com os índices fornecidos pelo skf.split\n",
    "        X_treino = X.iloc[idx_treino]\n",
    "        y_treino = y.iloc[idx_treino]\n",
    "        \n",
    "        #extrair as instâncias de teste de acordo com os índices fornecidos pelo skf.split\n",
    "        X_teste = X.iloc[idx_teste]\n",
    "        y_teste = y.iloc[idx_teste]\n",
    "        \n",
    "        #colocar todas as variáveis na mesma escala, usando o conjunto de treinamento para calcular os parâmetros da escala\n",
    "        ss = StandardScaler()\n",
    "        ss.fit(X_treino)\n",
    "        X_treino = ss.transform(X_treino)\n",
    "        X_teste = ss.transform(X_teste)\n",
    "        \n",
    "        #combinações de parametros otimizar. Aqui estamos apenas otimizando o número de vizinhos mais próximos para o knn (k).\n",
    "        #Entretanto, podemos colocar todos os valores de todos os parametros. O sklearn se encarrega de gerar todas as combinações.\n",
    "        params = {'n_neighbors' : range(1,30,2)}\n",
    "\n",
    "        #instanciar um KNN com parametros padrão\n",
    "        knn = KNeighborsClassifier()\n",
    "\n",
    "        #instanciar um GridSearchCV com k2 vias.\n",
    "        knn = GridSearchCV(knn, params, cv=StratifiedKFold(n_splits=k2), scoring=positive_accuracy_scorer)\n",
    "        \n",
    "        #realizar a otimização dos hiperparâmetros e treinar o modelo final com a melhor combinação de hiperparametros com todos os dados de treinamento\n",
    "        knn.fit(X_treino, y_treino)\n",
    "        \n",
    "        #calcular a acurácia no conjunto de testes desta iteração e salvar na lista.\n",
    "        # acuracias.append(accuracy_score(y_teste, knn.predict(X_teste)))\n",
    "        acuracias.append(positive_accuracy_scorer(knn, X_teste, y_teste))  # Use a métrica personalizada para calcular a acurácia\n",
    "        # acuracias.append(y_teste, knn.predict(X_teste))\n",
    "        # acuracias.append(positive_accuracy_scorer(y_teste, knn.predict(X_teste)))  # Use a métrica personalizada para calcular a acurácia\n",
    "        # acuracias.append(knn.best_score_)  # Use a métrica personalizada para calcular a acurácia da classe positiva\n",
    "        \n",
    "    #calcular as estatísticas da validação cruzada. Estas estatísticas nos dão uma confiança que, na média, este é o desempenho esperado\n",
    "    #do classificador no mundo real.\n",
    "    # print(\"min: %.2f, max: %.2f, avg +- std: %.2f+-%.2f\" % (min(acuracias), max(acuracias), np.mean(acuracias), np.std(acuracias)))\n",
    "    return acuracias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação cruzada em dois níveis com SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_svm():\n",
    "    k1 = 10 #controla o número de vias da validação cruzada para estimar o desempenho do modelo\n",
    "    k2 = 5 #controla o número de vida da validação cruzada para otimização de hiperparametros\n",
    "\n",
    "    positive_accuracy_scorer = make_scorer(custom_positive_accuracy)\n",
    "\n",
    "    #usar o protocolo de validação cruzada estratificada\n",
    "    skf = StratifiedKFold(n_splits=k1, shuffle=True, random_state=1)\n",
    "\n",
    "    acuracias = []\n",
    "\n",
    "    #a função split retorna os índices das instâncias que devem ser usadas para o treinamento e o teste.\n",
    "    for idx_treino, idx_teste in skf.split(X, y):\n",
    "        \n",
    "        #extrair as instâncias de treinamento de acordo com os índices fornecidos pelo skf.split\n",
    "        X_treino = X.iloc[idx_treino]\n",
    "        y_treino = y.iloc[idx_treino]\n",
    "        \n",
    "        #extrair as instâncias de teste de acordo com os índices fornecidos pelo skf.split\n",
    "        X_teste = X.iloc[idx_teste]\n",
    "        y_teste = y.iloc[idx_teste]\n",
    "        \n",
    "        #colocar todas as variáveis na mesma escala, usando o conjunto de treinamento para calcular os parâmetros da escala\n",
    "        ss = StandardScaler()\n",
    "        ss.fit(X_treino)\n",
    "        X_treino = ss.transform(X_treino)\n",
    "        X_teste = ss.transform(X_teste)\n",
    "        \n",
    "        #combinações de parametros otimizar. Aqui estamos apenas otimizando o número de vizinhos mais próximos para o knn (k).\n",
    "        #Entretanto, podemos colocar todos os valores de todos os parametros. O sklearn se encarrega de gerar todas as combinações.\n",
    "        params = {\n",
    "            'C': [0.1, 1, 10, 100, 1000],\n",
    "            'gamma': ['scale', 'auto', 2e-2, 2e-3, 2e-4],\n",
    "        }\n",
    "        #instanciar um SVM com parametros padrão\n",
    "        svm = SVC(kernel='rbf')\n",
    "\n",
    "        #instanciar um GridSearchCV com k2 vias.\n",
    "        svm = GridSearchCV(svm, params, cv=StratifiedKFold(n_splits=k2), scoring=positive_accuracy_scorer)\n",
    "\n",
    "        #realizar a otimização dos hiperparâmetros e treinar o modelo final com a melhor combinação de hiperparametros com todos os dados de treinamento\n",
    "        svm.fit(X_treino, y_treino)\n",
    "        \n",
    "        #calcular a acurácia no conjunto de testes desta iteração e salvar na lista.\n",
    "        # acuracias.append(accuracy_score(y_teste, svm.predict(X_teste)))\n",
    "        acuracias.append(positive_accuracy_scorer(svm, X_teste, y_teste))  # Use a métrica personalizada para calcular a acurácia\n",
    "        # acuracias.append(svm.best_score_)  # Use a métrica personalizada para calcular a acurácia da classe positiva\n",
    "        \n",
    "    #calcular as estatísticas da validação cruzada. Estas estatísticas nos dão uma confiança que, na média, este é o desempenho esperado\n",
    "    #do classificador no mundo real.\n",
    "    # print(\"min: %.2f, max: %.2f, avg +- std: %.2f+-%.2f\" % (min(acuracias), max(acuracias), np.mean(acuracias), np.std(acuracias)))\n",
    "    return acuracias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_estatisticas(resultados):\n",
    "    return np.mean(resultados), np.std(resultados), np.min(resultados), np.max(resultados)\n",
    "\n",
    "def imprimir_estatisticas(resultados):\n",
    "    media, desvio, mini, maxi = calcular_estatisticas(resultados)\n",
    "    print(\"Resultados: %.2f +- %.2f, min: %.2f, max: %.2f\" % (media, desvio, mini, maxi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs_knn = do_knn()\n",
    "accs_svm = do_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imprimir_estatisticas(accs_knn)\n",
    "imprimir_estatisticas(accs_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind_from_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculamos a média e o desvio padrão dos resultados\n",
    "media_knn, std_knn, _, _ = calcular_estatisticas(accs_knn)\n",
    "media_svm, std_svm, _, _ = calcular_estatisticas(accs_svm)\n",
    "\n",
    "#calcular o pvalor usando o teste t de Student para duas amostras independentes\n",
    "_, pvalor = ttest_ind_from_stats(media_knn, std_knn, len(accs_knn), media_svm, std_svm, len(accs_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejeitar_hip_nula(media_amostral1, desvio_padrao_amostral1, n1, media_amostral2, desvio_padrao_amostral2, n2, alpha=0.05):\n",
    "    _, pvalor = ttest_ind_from_stats(media_amostral1, desvio_padrao_amostral1, n1, media_amostral2, desvio_padrao_amostral2, n2)\n",
    "    return pvalor <= alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rejeitar_hip_nula(media_knn, std_knn, len(accs_knn), media_svm, std_svm, len(accs_svm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
